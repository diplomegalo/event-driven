# Event-Driven Microservices Fundamentals

- Un microservice _event driven_ est une application qui implémente les fonctionnalité d'un contexte limité.
- Les microservice _consomateurs_ consomment et traitent les events depuis une _event stream_.
- Les microservice _producteurs_ émettent des events sur l'_event stream_.
- Un microservice _event driven_ peut être à la fois _producteur_ et _consommateur_ et la communication entre eux est asynchrone.
- Les microservices peuvent être _stateless_ ou _stateful_ et peuvent contenir des appel synchrone à des services externes.
- L'events stream est accessible depuis un _event broker_.
- Le déploiement et la mise à l'échelle des microservices nécessite des outils de pipeline CI/CD et des outils de gestion de conteneurs.

## Building Topologies

### Microservices Topologies

Définis pour un microservice, les event streams en input, le traitement (filtering, transformation, aggregation, etc.) et les event streams en output, de même que les services externes appelés de manière synchrone.

### Business Topologies

Idem mais pour un ensemble de microservices. Le groupement des microservices en topologies permet de définir les interactions entre eux et est défini de manière arbitraire en fonction des besoins, par exemple par contexte métier, par domaine, par équipe, etc.

## The Content of an Event

Un événement représente tout ce qui peut être observé et significatif dans un cadre métier. Une fois émis, une événement peut être consommé est intégré dans un contexte (limité) métier.

Un événement enregistre un changement est représente la seule source de vérité. Il est immutable et contient des métadonnées et des données suffisamment précises pour être traitées par un consommateur.

## The Structure of an Event

Il existe trois type d'événements, tous représenté sous la forme clé/valeur où la clé peut être utile à l'identification, le routage et l'agrégation, alors que la valeur contient le détail complet de l'événement.

- **Unkeyed Events** : les événements sans clé sont utilisé pour les événements qui n'ont pas besoin d'être identifié de manière unique et qui décrivent un changement global. Par exemple, un événement de _heartbeat_.

- **Entity Events** : les événements d'entité représentent une entité unique où la clé est l'identifiant de celle-ci. Généralement, ces événements sont utilisés pour conserver un historique des changements d'une entité où le dernier événement est la source de vérité.

- **Keyed Event** : les événements à clé ne représentent pas une entité unique, mais une événement identifiable. Généralement ceux-ci sont enregistrés dans des streams différent sur base de leur types, assurant ainsi le partitionnement des événements permettant ensuite de retrouver les événements de manière efficace.

## Materializing State from Entity Events

Il existe de nombreux cas où un stream d'événements d'entité doit être transformé dans une representation de l'état courant d'un ensemble d'entités.

Il est possible de construire une table de record sur base des événements d'entité en prenant les derniers événements pour chaque entité.

L'inverse est également possible en prenant les événements de création, mise à jour et suppression d'un record dans une table pour les transformer en événements d'entité.

La suppression d'un record est représenté par un _tombstone event_ qui indique que l'entité n'existe plus en ayant une valeur à `null`.

Les événements (hors entité) peuvent augmenté de manière significative et prendre un espace de stockage important. Le service broker peut alors être configuré pour _compacter_ les événements en ne gardant que les événements les plus récents. Ce principes permet de faciliter la reconstruction de l'état courant. Dans le cas d'un événement de suppression, l'état courant n'en fait tout simplement plus référence.

## Event-Data Definition and Schema

Les données d'un événement servent de source de données long terme agnostique de l'implementation, mais également de moyen de communication entre les services. Les consommateurs ainsi que les producteurs est une compréhension commune de ces événements.

Il peut être intéressant d'intégrer des outils de manière pour éviter aux consommateurs de devoir s'adapter à chaque changement de schéma, de même que de fournir des outils de sérialisation/désérialisation pour faciliter la communication.

## Microservices Single Writer Principle

Le principe de _single writer_ est un principe de design qui stipule qu'un événement ne peut être émis que par un seul microservice. Cela permet de garantir que l'événement est émis de manière cohérente et que les consommateurs peuvent se fier à la source de vérité, mais également de pouvoir tracer l'origine d'un événement.

## Powering Microservices with the Event Broker

L'_event broker_ est le centre d'une architecture _event driven_. Il est responsable de récolter les événements, de les stocker dans des queues ou des streams et de les distribuer aux consommateurs.

Les _event brokers_ sont généralement distribués dans des clusters pour garantir la disponibilité et la résilience. Ils peuvent être configurés pour garantir la cohérence des événements, la réplication des données et la distribution des événements.

- **Scalability** : les _event brokers_ peuvent être mis à l'échelle en fonction de la charge en ajoutant des brokers supplémentaires.

- **Durability** : les données sont stockées de manière durable et peuvent être répliquées pour garantir la disponibilité.

- **High Availability** : les _event brokers_ sont généralement distribués dans des clusters pour garantir la disponibilité.

- **High Performance** : les _event brokers_ partage la charge de lecture et d'écriture entre eux pour garantir des performances élevées.

### Event Storage and Serving

Ci-dessous les règles de stockage et de distribution des événements :

- **Partitioning** : les _streams_ peuvent être partitionnés en fonction des besoins de performance. Ce partitionnement offre une opportunité de paralléliser le traitement des événements par les consommateurs. Les événements qui sont liés à une même ressource peuvent être regroupée par une stratégie définie par le développement. La stratégie la plus employée est d'écrire tous les événements partageant une même valeur de clé dans la même partition afin de garantir l'ordre des événements.

- **Strict Ordering** : Les événements doivent être stockés et distribués dans l'ordre dans lequel ils ont été émis par partition.

- **Immutability** : Les événements ne peuvent pas être modifiés une fois qu'ils ont été émis.

- **Indexing** : Les événements sont assignés à un index lors de leur stockage. Cet index est utilisé par le consommateur pour retrouver les événements de manière efficace, en stipulant l'_offset_. Celui-ci peut être utilisé pour des raisons de performance, car l'_event broker_ peut se rendre compte du nombre de messages à lire et par conséquent adapter le nombre de clients pour lire les messages.

- **Infinite retention** : Les événements doivent être stockés pour une durée indéterminée. C'est fondamental pour garantir la cohérence des données et la reconstitution de l'état courant.

- **Replayability** : Les événements doivent être stockés de manière à ce qu'ils puissent être rejoués à tout moment de manière à respecter le principe de source de vérité et de pouvoir garantir la communication entre les services.

## Event Brokers Versus Message Brokers

Les messages brokers ne peuvent pas être utilisés pour stocker des événements de manière durable et ne sont donc pas adaptés pour une architecture _event driven_.

| Event Broker | Message Broker |
|--------------|----------------|
| Stocke les événements de manière durable | Stocke les messages de manière temporaire |
| Utilise des streams pour stocker les événements | Utilise des queues pour stocker les messages |
| N'utilise pas de _dead letter queue_ | Utilise une _dead letter queue_ pour les messages non distribués |
| N'utilise pas d'accusé de réception | Utilise des accusés de réception pour garantir la distribution des messages |
| Permet l'accès à l'ensemble des événements de tous les streams | Permet l'accès aux messages non-consommés |

### Consuming from the Immutable Log

Généralement les événements sont stockés dans un _stream_ qui est un _immutable log_ où les événements sont stockés de manière séquentielle. Les consommateurs peuvent lire les événements soit comme un event stream, soit comme une queue.

#### Consuming as an Event Stream

Le consommateur est responsable de retenir l'_offset_ de lecture dans l'event stream. Cela permet à chaque consommateur de lire les événements de manière indépendante et de garantir la cohérence des données.

Un _consumer group_ est un groupe de microservice qui partage les mêmes _offset_ de lecture. Cela permet de paralléliser le traitement des événements sur plusieurs partition. Un _consumer group_ peut être mis à l'échelle en ajoutant des consommateurs supplémentaires pour lire les événements plus rapidement. Néanmoins, le nombre de consommateurs ne peut pas dépasser le nombre de partition, car chaque consommateur d'un _consumer group_ est associé à une partition de manière à lire les événements de manière séquentielle dans l'ordre (de la partition).

#### Consuming as a Queue

Les événements sont lus par un seul consommateur à la fois. Une fois qu'un événement est lu, il est marqué comme lu et ne peut plus être lu par un autre consommateur. L'ordre de lecture n'est pas garanti à partir du moment ou plusieurs consommateurs lisent les événements.

### Providing a Single Source of Truth

Le mécanisme de stockage des événements permet de garantir la cohérence des données et de fournir une source de vérité unique. Les événements stockés de manière durable peuvent être rejoués à tout moment pour garantir la cohérence des données.

Les bases de données traditionnelles peuvent encore être utiles dans le cadre de microservices pour stocker ou recopier des données utiles pour le traitement, mais seuls les événements stockés dans l'_event broker_ sont considérés comme source de vérité.
