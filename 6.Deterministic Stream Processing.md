# Deterministic Stream Processing

- Comment un microservice choisi l'ordre des événements à traiter lorsqu'il est consommateur de plusieurs partitions ?
- Comment un microservice gère les événements _out-of-order_ et _late-arriving_ ?
- Comment garantir qu'un microservice produise des résultats déterministes que ce soit lors d'un traitement d'un événement d'un stream en temps réel, ou lors d'une relecture complète des événements d'un stream ?

Ces questions peuvent avoir une réponse construite sur base de notions telles que les _timestamps_, les _watermarks_, l'event scheduling.

## Determinism with Event-Driven Workflow

Un microservice event-driven va soit fonctionner en temps (presque) réel où l'instance de celui-ci est toujours _up and running_ et les évènements sont traités dès leur arrivée, soit il va essayé de rattraper le retard accumulé en lisant plusieurs événements d'un stream par exemple dans le cas d'une nouvelle instance ou pour un microservice sous dimensionné. 

La question est : est-ce que si vous reveniez en arrière en remettant l'_offset_ du _consumer group_ au début de la stream, les résultats du traitement serait-il toujours identiques ? Par conséquent comment garantir le même résultat que ce soit en temps réel ou lors de rattrapage. 

Certains traitement ne sont pas déterministe, par exemple dans le cas où un service extérieur est nécessaire.

Pour tendre vers un déterminisme, malgré les problématiques lié à l'environnement ou aux erreurs, il faut un _timestamp_ cohérent, une clé d'évènement pertinente, un assignation de partition, un _event scheduling_, une stratégie pour gérer les événements _late arriving_.

## Timestamp

Les événements peuvent arriver n'importe où et à n'importe quel moment et doivent quelque fois être réconcilié avec d'autres événements émis par d'autres producteurs. Le _timestamp_ est un élément primordiale pour comparer des événements dans un système distribué.

Un événement est définie par un _offset_ et un _timestamp_ où ce dernier représente le moment où il a été créé et permet de garantir l'ordre dans lequel les événements doivent être livrés. Les 4 moments fondamentaux sont :

- **Event time** : le timestamp local du producteur.
- **Broker ingestion time** : le moment où l'événement est arrivé sur le broker. Si l'_event time_ est absent ou incorrect, le broker peut le remplacer par son propre _ingestion time_.
- **Consumer ingestion time** : le moment où l'événement est consommé par le microservice.
- **Processing time** : le moment où l'événement est traité par le microservice.

Le timestamp peut donc être utilisé par le consommateur pour ordonner les événements.

Comment sont générés ces _timestamps_ ?

### Synchronizing Distributed Timestamps

Les horloges des machines ne sont pas synchronisées et peuvent dériver. Pour garantir un ordre global, il faut synchroniser les horloges des machines grâce à des services comme NTP ou PTP. Néanmoins, ces services ne garantissent pas une précision absolue et il est possible que les horloges dérivent de plusieurs centaines de millisecondes. Sans compter les problèmes de latence réseau et de disponibilité des services. Néanmoins, pour la plupart des cas d'usage, une synchronisation régulière peut offrir une précision suffisante.

### Processing with Timestamped Events

Les _timestamps_ permettent de traiter les événements dans l'ordre dans un environnement distribué. Travailler avec les _offsets_ n'est suffisant que si le consommateur ne traite qu'une seule partition, or généralement un microservice consomme plusieurs partitions voire plusieurs _events streams_.

#### Example: Selecting order of events when processing multiple partitions

Dans le cas d'une banque, ayant deux _streams_ de transactions, un pour les dépôts et un pour les retraits, un microservice doit traiter les deux _streams_ pour calculer le solde du compte. L'ordre des événements à de l'importance à partir du moment où la banque applique des frais en cas de découvert. En effet, si un retrait est traité avant un dépôt, le solde du compte peut être négatif et des frais peuvent être appliqués alors qu'en réalité le compte est toujours resté positif.

## Event Scheduling and Deterministic Processing

L'_event scheduling_ est le processus de sélection du prochain événements à traiter sur base de l'ordre des _timestamps_. L'ordre des événements est également déterminé par la logique métier du microservice.

### Custom Event Schedulers

Les _event schedulers_ peuvent être implémentés selon des principes spécifiques à l'application. Attention toute fois que par nature, les _event schedulers_ ne sont pas déterministes et par conséquent, vont affecter la déterminisme du microservice.

### Processing Based On Event Time, Processing Time, and Ingestion Time

Ordonner les événements revient à faire le choix de quel timestamp utiliser pour ordonner les événements. L'_event time_ et le _broker ingestion time_ sont tous les deux des _timestamps_ qui n'arrivent qu'une seule fois et ne peuvent pas être modifiés, tandis que le _consumer ingestion time_ et le _processing time_ sont des _timestamps_ qui peuvent être modifiés par le consommateur en fonction du moment où il traite l'événement.

Dans la plupart des cas, surtout quand l'environnement est dans bon état et que les événement sont traités en temps (presque) réel, ces quatre _timestamps_ vont être relativement proches. Dans le cas contraire, où l'environnement présente des retards ou des erreurs et où les consommateurs doivent rattraper un retard, il y aura une grande différence entre l'_event time_ et le _consumer ingestion time_.

Le timestamp le plus proche de la réalité étant l'_event time_. Si celui-ci n'est pas suffisamment fiable, le _broker ingestion time_ peut être utilisé, car le risque que le producteur ne soit pas en mesure de publier un événement est faible est arrive peu fréquemment.

### Timestamp Extraction by the Consumer

Le consommateur doit pouvoir connaître la valeur des _timestamps_ pour choisir l'ordre des événements. Lors du _consumer ingestion time_, un _timestamp extractor_ est utilisé pour récupérer les données. Ce _timestamp extractor_ est capable de récupérer toutes les parties du _payload_ d'un event (la clé, les valeurs et les métadata).

### Request Response Calls to External Systems

Toute requête qui sort du cadre de l'event-driven, comme un call REST Web API synchrone, implique que le traitement n'est plus déterministe. Les services appelés sont gérés de manière autonome, ce qui implique que les réponses peuvent être différentes en fonction de l'état du service appelé.

### Watermarks

Les _watermarks_ sont utilisés pour tracker la progression des événements et ajoute une notion de temps au travers d'une topology. Ils permettent de déterminer que tous les événements précédents un temps _t_ ont été traité. Ils sont calculés en fonction des _timestamps_ des événements et permettent de déterminer si un événement est _late arriving_ lorsque le watermark est supérieur au _timestamp_ de l'événement. Le _watermark_ est également échangé entre les noeuds de la topology pour garantir que ceux-ci sont synchronisés. Les _watermarks_ sont très utile pour établir une fenêtre de temps d'exécution pour les événements.

### Stream Time

Les _stream time_ ont le même objectif que les _watermarks_. Le consommateur va maintenir dans sa stream time une notion de temps, basé sur les _timestamps_ des événements, pour déterminer l'ordre des événements.

## Out-of-Order and Late-Arriving Events

Lorsqu'un événement arrive dans le mauvais ordre, il est dit _out-of-order_. Dans le cas, d'un traitement par lot, ce cas de figure n'est pas un problème, mais dans le cas d'un traitement en temps réel, il est nécessaire de gérer ces événements dans l'implémentation pour garantir le déterminisme. Dans ce cas, le microservice peut maintenir un statut de traitement pour chaque événement pendant plusieurs heures pour garantir que les événements _out-of-order_ sont traités dans le bon ordre.

Les événements _late-arriving_ peuvent être définis comme tel uniquement d'un point de vue du consommateur. Chaque événement _out-of-order_ pourrait être systématiquement considéré comme _late-arriving_ dans un cas, tandis que dans un autre cas, un événement _out-of-order_ pourrait être considéré comme _late-arriving_ après plusieurs minutes, heures ou jours.

### Late Events with Watermarks and Stream Time

- **Watermark** : Dans le cas ou un événement _t'_ arrive après le _watermark_ _W(t)_ et que _t'_ est inférieur à _t_, alors _t'_ est considéré comme _late-arriving_.
- **Stream Time** : l'événement _t'_ est considéré comme _late-arriving_ après que le _stream time_ ait incrémenté ça dernière valeur à _t'_.

### Causes and Impacts of Out-of_Order Events

Les raisons d'un événement _out-of-order_ sont multiples :

- **Sourcing from out-of-order data** : les données sources d'un event stream peuvent être déjà être _out-of-order_. Par conséquent, les événements émis par les producteurs peuvent être _out-of-order_.
- **Multiple producers to multiple partitions** : les événements émis par plusieurs producteurs peuvent être distribués sur plusieurs partitions et donc arriver dans le mauvais ordre, par exemple lors du _repartitioning_.

### Time-Sensitive Functions and Windowing

Les événements tardif sont surtout problématique pour les fonctionnalités sensibles au temps comme les événements d'agrégation ou il faut garantir que les événements sont traités dans un ordre précis (débit et crédit d'un compte bancaire avec des frais en cas de découvert). Un événement tardif arrive après que la fenêtre de temps soit clôturée et que les traitements aient été effectués. La fenêtre de temps permet de regrouper les événements en fonction de leur _timestamp_, cela est particulièrement utile pour les événements avec une même clé. Il existe trois types de fenêtres :

- **Tumbling windows** : une fenêtre de temps de taille fixe qui se déplace en fonction au cours du temps sans chevauchement. Les fenêtres sont indépendants les unes des autres. Ce type de fenêtre est utile pour répondre à des questions du type "Quel est le nombre de transactions par jour ?".
- **Sliding windows** : une fenêtre de temps de taille fixe qui se déplace en fonction au cours du temps avec un chevauchement. Ce type de fenêtre est utile pour répondre à des questions du type "Quel est le nombre de transactions durant la dernière heure ?".
- **Session windows** : une fenêtre de taille dynamique qui se termine lorsqu'il n'y a plus d'événements pour une certaine période de temps et qui démarre lorsqu'un nouvel événement arrive après un timeout.

### Handling Late Events

Le choix de traiter ou non les événements _late-arriving_ dépend de la logique métier. Typiquement, des événements dans le cadre de transaction financière ne peuvent pas être ignorés, tandis que le relevé d'une sonde de température peut être ignoré si elle arrive trop tard.

- **Drop event** : l'événement est ignoré.
- **Wait** : la fenêtre de temps est prolongée pour attendre l'événement, ceci au profit du déterminisme, mais au dépens de la latence.
- **Grace period** : une période de grâce est définie pendant laquelle il est possible de modifier le traitement fait dans une fenêtre de temps. C'est la même chose que le wait, à l'exception que la fenêtre de temps peut être fermée et que le résultat est publié et peut être recalculé si un événement _late-arriving_ arrive.

### Reprocessing Versus Processing in Near Real-Time

Il est possible de rembobiner l'offset d'un _consumer group_ à un moment spécifique de manière arbitraire pour relire les événements, ça s'appelle le _reprocessing_. Le _reprocessing_ est essentiellement effectué pour les microservices qui se base sur l'_event time_ pour ordonner les événements. La gestion des événements _out-of-order_ est une partie importante de ce processus :

- **Determine the starting point** : la bonne pratique est de commencer à partir du début de la stream, car il est difficile de déterminer le moment exact où le traitement a échoué.
- **Determine which consumer offset to reset** : tous les consommateurs devraient effectué un _reprocessing_ pour garantir le déterminisme.
- **Consider the volume of data** : la quantité de données ingérable par les microservices et les éventuels bottleneck doit être pris en compte. Il peut être utile de prévenir les consommateur avant de lancer un _reprocessing_ de manière à ce qu'ils puissent adapter leur capacité de traitement.
- **Consider the time to reprocess** : le temps d'exécution peut être considérable, il faut donc considérer le temps de downtime des systèmes et éventuellement prendre des mesures pour garantir la continuité du service.
- **Consider the impact** : Certains microservices peuvent exécuté des actions qu'il ne devrait pas exécuter lors d'un _reprocessing_, comme l'envoi de notification (email, SMS, etc.).

### Intermittent Failures and Late Events

Un événement tardif pourrait ne pas avoir été pris en compte lors d'une première tentative de traitement en temps réel, mais pris en compte lors du _reprocessing_. Ces éléments sont très difficile à repérer et montre à quel point les problèmes de l'_upstream_ peuvent impacter les consommateurs _downstream_.

### Producer / Event Broker Connectivity Issues

Prenons l'exemple de deux producteurs publiant chacun des événements sur deux streams différentes, toutes deux consommés par un seul et même microservice. Si un des producteurs a des problèmes de connectivité avec le broker, les événements publiés par celui-ci ne seront pas consommés par le microservice et viendront bien plus tard lorsque la connexion sera rétablie. Ces événements seront considérés comme _late-arriving_ et ne seront potentiellement pas pris en compte lors du traitement initial. Néanmoins, lors d'un _reprocessing_, ces événements seront pris en compte et pourront impacter le résultat final.